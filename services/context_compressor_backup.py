#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šä¸‹æ–‡å‹ç¼©æœåŠ¡ - æ™ºèƒ½å‹ç¼©å†å²åŠ¨ä½œ
ç­–ç•¥ï¼šæ€»ç»“å†å² + ä¿ç•™æœ€æ–°
emmmä¸»è¦æ˜¯ä¿åº•çš„å‹ç¼©ï¼Œç›´æ¥æˆªå–çš„æ–¹æ³•ï¼Œç›®å‰æ˜¯è¢«å¼ƒç”¨çš„
"""

import sys
import json
from typing import List, Dict
from pathlib import Path

# ç¡®ä¿å¯ä»¥å¯¼å…¥å…¶ä»–æ¨¡å—
if __name__ == "__main__":
    sys.path.insert(0, str(Path(__file__).parent.parent))

from services.llm_client import SimpleLLMClient, ChatMessage

try:
    import tiktoken
    HAS_TIKTOKEN = True
except ImportError:
    HAS_TIKTOKEN = False
    print("âš ï¸ tiktokenæœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€å•ä¼°ç®—æ–¹æ³•")


class ContextCompressor:
    """ä¸Šä¸‹æ–‡å‹ç¼©å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å‹ç¼©å™¨"""
        self.llm_client = SimpleLLMClient()
        
        # åˆå§‹åŒ–tiktokenç¼–ç å™¨
        if HAS_TIKTOKEN:
            self.encoding = tiktoken.get_encoding("cl100k_base")
        else:
            self.encoding = None
    
    def count_tokens(self, text: str) -> int:
        """ç»Ÿè®¡æ–‡æœ¬çš„tokenæ•°"""
        if self.encoding:
            return len(self.encoding.encode(text))
        else:
            # ç®€å•ä¼°ç®—ï¼šä¸­æ–‡1.5å­—ç¬¦/tokenï¼Œè‹±æ–‡4å­—ç¬¦/token
            chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
            other_chars = len(text) - chinese_chars
            return int(chinese_chars / 1.5 + other_chars / 4)
    
    def compress_action_history(
        self,
        action_history: List[Dict],
        max_allowed_tokens: int
    ) -> List[Dict]:
        """
        å‹ç¼©å†å²åŠ¨ä½œ
        
        ç­–ç•¥ï¼š
        1. ä¿ç•™æœ€è¿‘1æ¡actionï¼ˆå®Œæ•´ï¼‰
        2. æ€»ç»“ä¹‹å‰æ‰€æœ‰actionä¸ºä¸€æ®µè¯
        3. å¦‚æœæœ€è¿‘1æ¡è¶…è¿‡(max_allowed - 20k)ï¼Œåˆ†æ®µå‹ç¼©å®ƒ
        
        Args:
            action_history: åŸå§‹åŠ¨ä½œå†å²
            max_allowed_tokens: å…è®¸çš„æœ€å¤§tokenæ•°
            
        Returns:
            å‹ç¼©åçš„åŠ¨ä½œå†å²
        """
        if not action_history:
            return []
        
        if len(action_history) == 1:
            # åªæœ‰ä¸€æ¡ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
            single_action = action_history[0]
            single_tokens = self.count_tokens(json.dumps(single_action, ensure_ascii=False))
            
            if single_tokens > max_allowed_tokens - 20000:
                print(f"ğŸ”„ å•æ¡actionè¿‡å¤§ ({single_tokens} tokens)ï¼Œè¿›è¡Œåˆ†æ®µå‹ç¼©")
                return [self._compress_large_action(single_action, max_allowed_tokens - 20000)]
            else:
                return action_history
        
        # å¤šæ¡actionçš„æƒ…å†µ
        recent_action = action_history[-1]  # æœ€è¿‘çš„ä¸€æ¡
        historical_actions = action_history[:-1]  # ä¹‹å‰çš„æ‰€æœ‰
        
        # æ£€æŸ¥æœ€è¿‘ä¸€æ¡çš„å¤§å°
        recent_tokens = self.count_tokens(json.dumps(recent_action, ensure_ascii=False))
        
        if recent_tokens > max_allowed_tokens - 20000:
            # æœ€è¿‘ä¸€æ¡æœ¬èº«å°±å¤ªå¤§ï¼Œéœ€è¦å‹ç¼©
            print(f"ğŸ”„ æœ€è¿‘actionè¿‡å¤§ ({recent_tokens} tokens)ï¼Œè¿›è¡Œåˆ†æ®µå‹ç¼©")
            compressed_recent = self._compress_large_action(recent_action, max_allowed_tokens - 20000)
            
            # å†å²éƒ¨åˆ†æ€»ç»“
            if historical_actions:
                summary_action = self._summarize_historical_actions(historical_actions)
                return [summary_action, compressed_recent]
            else:
                return [compressed_recent]
        else:
            # æœ€è¿‘ä¸€æ¡æ­£å¸¸ï¼Œæ€»ç»“å†å²
            summary_action = self._summarize_historical_actions(historical_actions)
            
            # æ£€æŸ¥æ€»å¤§å°
            total_tokens = self.count_tokens(json.dumps([summary_action, recent_action], ensure_ascii=False))
            
            if total_tokens <= max_allowed_tokens:
                return [summary_action, recent_action]
            else:
                # æ€»ç»“ä¹Ÿå¤ªå¤§äº†ï¼Œè¿›ä¸€æ­¥å‹ç¼©æ€»ç»“
                print(f"âš ï¸ æ€»ç»“åä»è¶…é™ ({total_tokens} tokens)ï¼Œä½¿ç”¨æç®€æ€»ç»“")
                # ç›´æ¥è¿”å›ä¸€ä¸ªè¶…ç®€å•çš„æ€»ç»“ + æœ€è¿‘action
                simple_summary = self._create_simple_summary(historical_actions)
                return [simple_summary, recent_action]
    
    def _summarize_historical_actions(self, actions: List[Dict]) -> Dict:
        """
        å°†å†å²actionsæ€»ç»“ä¸ºä¸€æ®µè¯
        
        Args:
            actions: å†å²actionåˆ—è¡¨
            
        Returns:
            ä¸€ä¸ªç‰¹æ®Šçš„"æ€»ç»“action"
        """
        try:
            # æ„å»ºå†å²æ‘˜è¦
            summary_text = f"å†å²å…±{len(actions)}ä¸ªåŠ¨ä½œï¼š\n"
            
            # ç»Ÿè®¡å·¥å…·ä½¿ç”¨æƒ…å†µ
            tool_counts = {}
            for action in actions:
                tool_name = action.get("tool_name", "unknown")
                tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1
            
            summary_text += "\nå·¥å…·è°ƒç”¨ç»Ÿè®¡ï¼š\n"
            for tool, count in tool_counts.items():
                summary_text += f"- {tool}: {count}æ¬¡\n"
            
            # æå–å…³é”®ç»“æœ
            summary_text += "\nå…³é”®ç»“æœï¼š\n"
            for i, action in enumerate(actions[-5:], 1):  # æœ€å5ä¸ªçš„æ‘˜è¦
                tool_name = action.get("tool_name", "")
                status = action.get("result", {}).get("status", "unknown")
                summary_text += f"{i}. {tool_name} - {status}\n"
            
            # è°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½æ€»ç»“
            prompt = f"""è¯·å°†ä»¥ä¸‹å†å²åŠ¨ä½œæ€»ç»“ä¸ºä¸€æ®µç®€æ´çš„æè¿°ï¼ˆä¸è¶…è¿‡500 tokensï¼‰ï¼š

{summary_text}

å†å²åŠ¨ä½œè¯¦æƒ…ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
{json.dumps(actions, ensure_ascii=False, indent=2)[:5000]}...

è¦æ±‚ï¼š
1. æ€»ç»“å®Œæˆäº†ä»€ä¹ˆå·¥ä½œ
2. å…³é”®çš„è¾“å‡ºå’Œæ–‡ä»¶
3. é‡è¦çš„å‘ç°æˆ–ç»“æœ
4. ç®€æ´ä½†å®Œæ•´

è¯·ç”¨ä¸­æ–‡æ€»ç»“ï¼š"""
            
            history = [ChatMessage(role="user", content=prompt)]
            
            response = self.llm_client.chat(
                history=history,
                model=self.llm_client.models[0],
                system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ€»ç»“åŠ©æ‰‹ã€‚",
                tool_list=[],
                tool_choice="auto"
            )
            
            if response.status == "success":
                summary = response.output
            else:
                summary = summary_text  # ä½¿ç”¨ç»Ÿè®¡æ‘˜è¦ä½œä¸ºå¤‡ç”¨
            
            # åˆ›å»ºæ€»ç»“action
            return {
                "tool_name": "_historical_summary",
                "arguments": {
                    "action_count": len(actions),
                    "summary_method": "llm_summarization"
                },
                "result": {
                    "status": "success",
                    "output": f"[å†å²åŠ¨ä½œæ€»ç»“] {summary}",
                    "_is_summary": True,
                    "_summarized_count": len(actions)
                }
            }
        
        except Exception as e:
            print(f"âš ï¸ æ€»ç»“å¤±è´¥: {e}")
            # å¤±è´¥æ—¶ä½¿ç”¨ç®€å•ç»Ÿè®¡
            return self._create_simple_summary(actions)
    
    def _create_simple_summary(self, actions: List[Dict]) -> Dict:
        """åˆ›å»ºç®€å•çš„ç»Ÿè®¡æ€»ç»“ï¼ˆä¸è°ƒç”¨LLMï¼‰"""
        tool_counts = {}
        for action in actions:
            tool_name = action.get("tool_name", "unknown")
            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1
        
        summary = f"å†å²å…±{len(actions)}ä¸ªåŠ¨ä½œã€‚"
        summary += "å·¥å…·ä½¿ç”¨: " + ", ".join([f"{t}({c}æ¬¡)" for t, c in tool_counts.items()])
        
        return {
            "tool_name": "_historical_summary",
            "arguments": {"action_count": len(actions)},
            "result": {
                "status": "success",
                "output": f"[å†å²åŠ¨ä½œç®€è¦æ€»ç»“] {summary}",
                "_is_summary": True,
                "_summarized_count": len(actions)
            }
        }
    
    def _compress_large_action(self, action: Dict, max_tokens: int) -> Dict:
        """
        å‹ç¼©å•ä¸ªè¶…å¤§action
        
        ç­–ç•¥ï¼šåªå‹ç¼©result.outputéƒ¨åˆ†
        
        Args:
            action: åŸå§‹action
            max_tokens: æœ€å¤§å…è®¸tokenæ•°
            
        Returns:
            å‹ç¼©åçš„action
        """
        tool_name = action.get("tool_name", "")
        arguments = action.get("arguments", {})
        result = action.get("result", {})
        
        output = result.get("output", "")
        output_tokens = self.count_tokens(output)
        
        if output_tokens > max_tokens:
            print(f"   å‹ç¼©{tool_name}çš„output: {output_tokens} tokens â†’ ç›®æ ‡ {max_tokens} tokens")
            
            # ç­–ç•¥ï¼šé¦–å°¾ä¿ç•™æ³•ï¼ˆä½¿ç”¨tiktokenç²¾ç¡®æˆªå–ï¼‰
            if self.encoding:
                # ä½¿ç”¨tiktokenç²¾ç¡®æˆªå–
                tokens = self.encoding.encode(output)
                
                # é¦–å°¾å„ä¿ç•™40%çš„ç›®æ ‡tokenï¼ˆæ€»å…±80%ï¼‰
                head_tokens_count = int(max_tokens * 0.4)
                tail_tokens_count = int(max_tokens * 0.4)
                
                head_tokens = tokens[:head_tokens_count]
                tail_tokens = tokens[-tail_tokens_count:]
                
                head_text = self.encoding.decode(head_tokens)
                tail_text = self.encoding.decode(tail_tokens)
                
                middle_info = f"\n\n[ä¸­é—´çœç•¥çº¦ {output_tokens - max_tokens} tokens]\n\n"
                
                compressed_output = head_text + middle_info + tail_text
            else:
                # æ²¡æœ‰tiktokenï¼Œç®€å•æˆªæ–­ï¼ˆä¿å®ˆä¼°è®¡ï¼‰
                chars_to_keep = int(max_tokens * 2)  # 1 token â‰ˆ 2å­—ç¬¦
                head_chars = chars_to_keep // 2
                tail_chars = chars_to_keep // 2
                
                compressed_output = output[:head_chars] + "\n\n[ä¸­é—´çœç•¥]\n\n" + output[-tail_chars:]
            
            # éªŒè¯å‹ç¼©æ•ˆæœ
            compressed_tokens = self.count_tokens(compressed_output)
            print(f"   å‹ç¼©ç»“æœ: {compressed_tokens} tokens (å‹ç¼©æ¯”: {compressed_tokens/output_tokens*100:.1f}%)")
            
            return {
                "tool_name": tool_name,
                "arguments": arguments,
                "result": {
                    **result,
                    "output": compressed_output,
                    "_compressed": True,
                    "_original_tokens": output_tokens,
                    "_compressed_tokens": compressed_tokens
                },
                "timestamp": action.get("timestamp", "")
            }
        
        return action


if __name__ == "__main__":
    # æµ‹è¯•æ—¶ä¸å®é™…è¿è¡ŒLLMï¼Œåªæµ‹è¯•é€»è¾‘
    print("âœ… ContextCompressoræ¨¡å—åŠ è½½æˆåŠŸ")
    print("åŠŸèƒ½ï¼š")
    print("  1. æ€»ç»“å†å²actionsä¸ºä¸€æ®µè¯")
    print("  2. ä¿ç•™æœ€è¿‘1æ¡action")
    print("  3. å¦‚æœæœ€è¿‘1æ¡è¶…å¤§ï¼Œä½¿ç”¨é¦–å°¾ä¿ç•™æ³•å‹ç¼©")
    print("\nç­–ç•¥ï¼šå†å²æ€»ç»“ + æœ€æ–°å®Œæ•´ = æœ€ä½³å¹³è¡¡")
